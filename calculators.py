"""
–ú–æ–¥—É–ª—å —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Ä–∞—Å—á—ë—Ç–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤.
"""
import logging
import time
import database
from typing import Dict, Any


def calculate_kafka_sizing(params: Dict[str, Any]) -> Dict[str, Any]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è Kafka –∫–ª–∞—Å—Ç–µ—Ä–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

    :param params: –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:
        - messages_per_sec: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
        - message_size_kb: —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ö–ë
        - retention_hours: –≤—Ä–µ–º—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —á–∞—Å–∞—Ö
        - replication_factor: —Ñ–∞–∫—Ç–æ—Ä —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏
    :param user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è Telegram
    :param additional_conditions: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    :param ai_adjustments: –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏, –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–µ –ò–ò
    :return: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ä–∞—Å—á—ë—Ç–∞ –∏ ID —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ —Ä–∞—Å—á—ë—Ç–∞
    """
    try:
        messages_per_sec = params.get('messages_per_sec', 1000)
        message_size_kb = params.get('message_size_kb', 1)
        retention_hours = params.get('retention_hours', 24)
        replication_factor = params.get('replication_factor', 3)

        # –†–∞—Å—á—ë—Ç –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
        throughput_mb_sec = (messages_per_sec * message_size_kb) / 1024

        # –†–∞—Å—á—ë—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        daily_data_gb = (throughput_mb_sec * 3600 * retention_hours) / 1024
        storage_needed_gb = daily_data_gb * replication_factor

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –±—Ä–æ–∫–µ—Ä–æ–≤
        brokers_count = max(3, replication_factor)

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–∞–º—è—Ç–∏ –Ω–∞ –±—Ä–æ–∫–µ—Ä
        ram_per_broker_gb = max(8, int(storage_needed_gb / brokers_count / 10))

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ CPU –Ω–∞ –±—Ä–æ–∫–µ—Ä
        cpu_per_broker = max(4, int(messages_per_sec / 5000))

        result = {
            'throughput_mb_sec': round(throughput_mb_sec, 2),
            'storage_needed_gb': round(storage_needed_gb, 2),
            'brokers_count': brokers_count,
            'ram_per_broker_gb': ram_per_broker_gb,
            'cpu_per_broker': cpu_per_broker,
            'storage_per_broker_gb': round(storage_needed_gb / brokers_count * 1.2, 2),
            'replication_factor': replication_factor,
            'message_size_kb': message_size_kb,
            'retention_hours': retention_hours,
            'messages_per_sec': messages_per_sec,
            'calculated_at': time.strftime('%Y-%m-%d %H:%M:%S')
        }

        logging.info(f'Kafka sizing calculated: {result}')
        return result
    except Exception as error:
        logging.error(f'–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ Kafka sizing: {error}')
        return {'error': str(error)}


def calculate_k8s_sizing(params: Dict[str, Any]) -> Dict[str, Any]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è Kubernetes –∫–ª–∞—Å—Ç–µ—Ä–∞.
    
    :param params: –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:
        - pods_count: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–æ–≤
        - avg_cpu_per_pod: —Å—Ä–µ–¥–Ω–∏–π CPU –Ω–∞ –ø–æ–¥
        - avg_ram_per_pod_gb: —Å—Ä–µ–¥–Ω—è—è RAM –Ω–∞ –ø–æ–¥ –≤ –ì–ë
        - high_availability: —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ HA
    :return: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ä–∞—Å—á—ë—Ç–∞
    """
    try:
        pods_count = params.get('pods_count', 50)
        avg_cpu_per_pod = params.get('avg_cpu_per_pod', 0.5)
        avg_ram_per_pod_gb = params.get('avg_ram_per_pod_gb', 1)
        high_availability = params.get('high_availability', True)
        
        # –û–±—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–¥–æ–≤
        total_cpu = pods_count * avg_cpu_per_pod
        total_ram_gb = pods_count * avg_ram_per_pod_gb
        
        # –ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã –Ω–∞ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ–¥—ã (10-20%)
        system_overhead = 1.2
        total_cpu_with_overhead = total_cpu * system_overhead
        total_ram_with_overhead = total_ram_gb * system_overhead
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–¥
        min_nodes = 3 if high_availability else 1
        cpu_per_node = 8  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –Ω–æ–¥–∞
        ram_per_node = 32  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –Ω–æ–¥–∞
        
        nodes_by_cpu = max(min_nodes, int(total_cpu_with_overhead / cpu_per_node) + 1)
        nodes_by_ram = max(min_nodes, int(total_ram_with_overhead / ram_per_node) + 1)
        
        nodes_count = max(nodes_by_cpu, nodes_by_ram)
        
        # Control plane
        control_plane_nodes = 3 if high_availability else 1
        
        result = {
            'total_cpu_required': round(total_cpu_with_overhead, 2),
            'total_ram_gb_required': round(total_ram_with_overhead, 2),
            'worker_nodes_count': nodes_count,
            'control_plane_nodes': control_plane_nodes,
            'recommended_node_size': f'{cpu_per_node} vCPU, {ram_per_node} GB RAM',
            'total_nodes': nodes_count + control_plane_nodes
        }
        
        logging.info(f'K8s sizing calculated: {result}')
        return result
    except Exception as error:
        logging.error(f'–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ K8s sizing: {error}')
        return {}


def calculate_redis_sizing(params: Dict[str, Any]) -> Dict[str, Any]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è Redis –∫–ª–∞—Å—Ç–µ—Ä–∞.
    
    :param params: –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:
        - dataset_size_gb: —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –≤ –ì–ë
        - operations_per_sec: –æ–ø–µ—Ä–∞—Ü–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
        - high_availability: —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ HA
        - persistence: —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
    :return: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ä–∞—Å—á—ë—Ç–∞
    """
    try:
        dataset_size_gb = params.get('dataset_size_gb', 10)
        operations_per_sec = params.get('operations_per_sec', 10000)
        high_availability = params.get('high_availability', True)
        persistence = params.get('persistence', True)
        
        # –ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã Redis (fragmentation, etc)
        memory_overhead = 1.5 if persistence else 1.3
        total_memory_gb = dataset_size_gb * memory_overhead
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è RAM –Ω–∞ –∏–Ω—Å—Ç–∞–Ω—Å (–Ω–µ –±–æ–ª–µ–µ 64 GB –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã)
        max_ram_per_instance = 64
        instances_count = max(1, int(total_memory_gb / max_ram_per_instance) + 1)
        
        # HA –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (master + replicas)
        if high_availability:
            total_instances = instances_count * 2  # master + replica
            replicas = instances_count
        else:
            total_instances = instances_count
            replicas = 0
        
        # CPU —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (Redis –æ–¥–Ω–æ–ø–æ—Ç–æ—á–Ω—ã–π, –Ω–æ –Ω—É–∂–Ω—ã –∑–∞–ø–∞—Å)
        cpu_per_instance = max(4, int(operations_per_sec / 50000))
        
        # Disk –¥–ª—è persistence
        disk_per_instance_gb = 0
        if persistence:
            disk_per_instance_gb = round((total_memory_gb / instances_count) * 1.5, 2)
        
        result = {
            'total_memory_gb': round(total_memory_gb, 2),
            'master_instances': instances_count,
            'replica_instances': replicas,
            'total_instances': total_instances,
            'ram_per_instance_gb': round(total_memory_gb / instances_count, 2),
            'cpu_per_instance': cpu_per_instance,
            'disk_per_instance_gb': disk_per_instance_gb
        }
        
        logging.info(f'Redis sizing calculated: {result}')
        return result
    except Exception as error:
        logging.error(f'–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ Redis sizing: {error}')
        return {}


def calculate_rabbitmq_sizing(params: Dict[str, Any]) -> Dict[str, Any]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è RabbitMQ –∫–ª–∞—Å—Ç–µ—Ä–∞.
    
    :param params: –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:
        - messages_per_sec: —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
        - message_size_kb: —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ö–ë
        - queue_depth: –≥–ª—É–±–∏–Ω–∞ –æ—á–µ—Ä–µ–¥–∏ (—Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π)
        - high_availability: —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ HA
    :return: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ä–∞—Å—á—ë—Ç–∞
    """
    try:
        messages_per_sec = params.get('messages_per_sec', 1000)
        message_size_kb = params.get('message_size_kb', 10)
        queue_depth = params.get('queue_depth', 10000)
        high_availability = params.get('high_availability', True)
        
        # –†–∞—Å—á—ë—Ç –ø–∞–º—è—Ç–∏ –¥–ª—è –æ—á–µ—Ä–µ–¥–µ–π
        queue_memory_gb = (queue_depth * message_size_kb) / (1024 * 1024)
        
        # –ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã RabbitMQ
        system_overhead = 2.0
        total_memory_gb = queue_memory_gb * system_overhead
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–¥
        nodes_count = 3 if high_availability else 1
        
        # RAM –Ω–∞ –Ω–æ–¥—É (–º–∏–Ω–∏–º—É–º 8 GB)
        ram_per_node_gb = max(8, int(total_memory_gb / nodes_count))
        
        # CPU –Ω–∞ –Ω–æ–¥—É
        cpu_per_node = max(4, int(messages_per_sec / 10000))
        
        # Disk –¥–ª—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        disk_per_node_gb = ram_per_node_gb * 2
        
        # –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å
        throughput_mb_sec = (messages_per_sec * message_size_kb) / 1024
        
        result = {
            'nodes_count': nodes_count,
            'ram_per_node_gb': ram_per_node_gb,
            'cpu_per_node': cpu_per_node,
            'disk_per_node_gb': disk_per_node_gb,
            'throughput_mb_sec': round(throughput_mb_sec, 2),
            'total_memory_gb': round(total_memory_gb, 2),
            'queue_memory_gb': round(queue_memory_gb, 2)
        }
        
        logging.info(f'RabbitMQ sizing calculated: {result}')
        return result
    except Exception as error:
        logging.error(f'–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ RabbitMQ sizing: {error}')
        return {}


def format_result(service_type: str, result: Dict[str, Any], ai_comment: str = None) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å—á—ë—Ç–∞ –≤ —á–∏—Ç–∞–µ–º—É—é —Å—Ç—Ä–æ–∫—É.
    
    :param service_type: –¢–∏–ø —Å–µ—Ä–≤–∏—Å–∞
    :param result: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å—á—ë—Ç–∞
    :param ai_comment: –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ—Ç –ò–ò –æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞—Ö
    :return: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
    """
    if not result:
        return "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á—ë—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."
    
    ai_section = ""
    if ai_comment:
        ai_section = f"\nü§ñ –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –ò–ò:\n{ai_comment}\n"
    
    if service_type == 'kafka':
        return f"""
üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å—á—ë—Ç–∞ –¥–ª—è Kafka:

üî∏ –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {result['throughput_mb_sec']} –ú–ë/—Å–µ–∫
üî∏ –ù–µ–æ–±—Ö–æ–¥–∏–º–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {result['storage_needed_gb']} –ì–ë
üî∏ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—Ä–æ–∫–µ—Ä–æ–≤: {result['brokers_count']}
üî∏ RAM –Ω–∞ –±—Ä–æ–∫–µ—Ä: {result['ram_per_broker_gb']} –ì–ë
üî∏ CPU –Ω–∞ –±—Ä–æ–∫–µ—Ä: {result['cpu_per_broker']} —è–¥–µ—Ä
üî∏ –•—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ –±—Ä–æ–∫–µ—Ä: {result['storage_per_broker_gb']} –ì–ë
{ai_section}"""
    
    elif service_type == 'kubernetes':
        return f"""
üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å—á—ë—Ç–∞ –¥–ª—è Kubernetes:

üî∏ –¢—Ä–µ–±—É–µ—Ç—Å—è CPU: {result['total_cpu_required']} —è–¥–µ—Ä
üî∏ –¢—Ä–µ–±—É–µ—Ç—Å—è RAM: {result['total_ram_gb_required']} –ì–ë
üî∏ Worker-–Ω–æ–¥—ã: {result['worker_nodes_count']}
üî∏ Control Plane –Ω–æ–¥—ã: {result['control_plane_nodes']}
üî∏ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –Ω–æ–¥—ã: {result['recommended_node_size']}
üî∏ –í—Å–µ–≥–æ –Ω–æ–¥: {result['total_nodes']}
{ai_section}"""
    
    elif service_type == 'redis':
        return f"""
üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å—á—ë—Ç–∞ –¥–ª—è Redis:

üî∏ –û–±—â–∞—è –ø–∞–º—è—Ç—å: {result['total_memory_gb']} –ì–ë
üî∏ Master –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤: {result['master_instances']}
üî∏ Replica –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤: {result['replica_instances']}
üî∏ –í—Å–µ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤: {result['total_instances']}
üî∏ RAM –Ω–∞ –∏–Ω—Å—Ç–∞–Ω—Å: {result['ram_per_instance_gb']} –ì–ë
üî∏ CPU –Ω–∞ –∏–Ω—Å—Ç–∞–Ω—Å: {result['cpu_per_instance']} —è–¥–µ—Ä
üî∏ –î–∏—Å–∫ –Ω–∞ –∏–Ω—Å—Ç–∞–Ω—Å: {result['disk_per_instance_gb']} –ì–ë
{ai_section}"""
    
    elif service_type == 'rabbitmq':
        return f"""
üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å—á—ë—Ç–∞ –¥–ª—è RabbitMQ:

üî∏ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–¥: {result['nodes_count']}
üî∏ RAM –Ω–∞ –Ω–æ–¥—É: {result['ram_per_node_gb']} –ì–ë
üî∏ CPU –Ω–∞ –Ω–æ–¥—É: {result['cpu_per_node']} —è–¥–µ—Ä
üî∏ –î–∏—Å–∫ –Ω–∞ –Ω–æ–¥—É: {result['disk_per_node_gb']} –ì–ë
üî∏ –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {result['throughput_mb_sec']} –ú–ë/—Å–µ–∫
üî∏ –ü–∞–º—è—Ç—å –¥–ª—è –æ—á–µ—Ä–µ–¥–µ–π: {result['queue_memory_gb']} –ì–ë
üî∏ –û–±—â–∞—è –ø–∞–º—è—Ç—å: {result['total_memory_gb']} –ì–ë
{ai_section}"""
    
    return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å–µ—Ä–≤–∏—Å–∞."


def format_history_item(calculation: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞—Å—á—ë—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    :param calculation: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Ä–∞—Å—á—ë—Ç–∞
    :return: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
    """
    service_names = {
        'kafka': '‚òï Kafka',
        'kubernetes': '‚éà Kubernetes',
        'redis': 'üóÑÔ∏è Redis',
        'rabbitmq': 'üê∞ RabbitMQ'
    }

    service_name = service_names.get(calculation['service_type'], calculation['service_type'])

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    input_params_text = ""
    if calculation['service_type'] == 'kafka':
        input_params_text = f"{calculation['input_params'].get('messages_per_sec', 0)} msg/sec, {calculation['input_params'].get('message_size_kb', 0)} KB/msg"
    elif calculation['service_type'] == 'kubernetes':
        input_params_text = f"{calculation['input_params'].get('pods_count', 0)} –ø–æ–¥–æ–≤, HA: {'–¥–∞' if calculation['input_params'].get('high_availability') else '–Ω–µ—Ç'}"
    elif calculation['service_type'] == 'redis':
        input_params_text = f"{calculation['input_params'].get('dataset_size_gb', 0)} GB –¥–∞–Ω–Ω—ã—Ö, {calculation['input_params'].get('operations_per_sec', 0)} ops/sec"
    elif calculation['service_type'] == 'rabbitmq':
        input_params_text = f"{calculation['input_params'].get('messages_per_sec', 0)} msg/sec, {calculation['input_params'].get('queue_depth', 0)} –≤ –æ—á–µ—Ä–µ–¥–∏"

    return f"""
üìÖ {calculation['created_at']}
{service_name}
üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {input_params_text}
ü§ñ –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏: {calculation['ai_adjustments']}
"""